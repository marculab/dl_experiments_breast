{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "import scipy.io.wavfile\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout, BatchNormalization, MaxPooling1D, AveragePooling1D\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam, SGD, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load wav as arrays\n",
    "audio_path = Path('../dataset/UrbanSound8K/audio')\n",
    "def load_wav_fold(fold_id):\n",
    "    p = audio_path.joinpath('fold'+str(fold_id))\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    for f in p.iterdir():\n",
    "        if f.is_file():\n",
    "            parts = f.parts\n",
    "            fname = parts[-1]\n",
    "            ## get label from file name\n",
    "            ftype = fname.split('.')[-1]\n",
    "            if ftype != 'wav':\n",
    "                continue\n",
    "            label = fname.split('-')[1]\n",
    "            try:\n",
    "                rate, arr = scipy.io.wavfile.read(str(f))\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "            if len(arr.shape) > 1:\n",
    "                arr = arr[:, 0]\n",
    "            x_arr.append(arr)\n",
    "            y_arr.append(label)\n",
    "    x_arr = np.array(x_arr) ## only keep the first dimension\n",
    "    y_arr = np.array(y_arr)\n",
    "    return x_arr, y_arr\n",
    "\n",
    "def apply_resample(foldarr, outdim):\n",
    "    for idx in range(foldarr.shape[0]):\n",
    "        foldarr[idx] = resample(foldarr[idx], outdim)\n",
    "    return foldarr\n",
    "\n",
    "def get_xtrain_mean(x_train):\n",
    "    ## mean value for each dimension (exp. each of 625 dim)\n",
    "    m = np.mean(x_train, axis=0)\n",
    "    ## then we can apply x_train - m for zero mean\n",
    "    return m\n",
    "\n",
    "def combine_samples(arrs):\n",
    "    ## exp. arrs.shape: (20, ?)\n",
    "    if arrs.shape[0] < 1:\n",
    "        return arrs\n",
    "    sp = list(arrs[0].shape)\n",
    "    sp[0] = 0\n",
    "    combined = np.zeros(sp)\n",
    "    print(\"combinde\", combined.shape)\n",
    "    for sample in range(arrs.shape[0]):\n",
    "        arr = arrs[sample]\n",
    "        combined = np.concatenate((combined, arr), axis=0)\n",
    "    return combined\n",
    "\n",
    "def save_to_npy(x, y, fold_id):  \n",
    "    np.save(audio_path.joinpath('fold{}_x.npy'.format(fold_id)), x)\n",
    "    np.save(audio_path.joinpath('fold{}_y.npy'.format(fold_id)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10, 11):    \n",
    "#     x_arr, y_arr = load_wav_fold(i)\n",
    "#     print(\"x_arr\", x_arr.shape)\n",
    "#     x_arr = apply_resample(x_arr, 32000)\n",
    "#     save_to_npy(x_arr, y_arr, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## global parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models to test\n",
    "* VERY DEEP CONVOLUTIONAL NEURAL NETWORKS FOR RAW WAVEFORMS\n",
    "\n",
    "they have a clearly defined structure, and their data are of similar dimentions\n",
    "\n",
    "* Raw Waveform-based Audio Classification Using Sample-level CNN Architectures\n",
    "* SAMPLE-LEVEL DEEP CONVOLUTIONAL NEURAL NETWORKS FOR MUSIC AUTO-TAGGING USING RAW WAVEFORMS\n",
    "\n",
    "realtively simple arch;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test raw waveform input first\n",
    "* input: 2500 * 1 waveform (normalized, center to 0, variance 1)\n",
    "* conv layer: with/withour overlapping. In the paper:\n",
    "    * filter size 3, stride 3, 128 filters\n",
    "    * filter size 80, stride 4, 256 filters\n",
    "* batch normalization: after every conv layer\n",
    "* max pool\n",
    "    * stride of 3? 4?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input\n",
    "or we can make the input as 625 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model\n",
    "## 1d conv, size 4 filter, 64 filters, stride 2\n",
    "## output 1250 * 64\n",
    "## batch norm\n",
    "## maxpool 2 * 1\n",
    "## output 625 * 64\n",
    "## 1d conv, size 3 filter, stride 2, 128 filters\n",
    "## maxpool 2 * 1\n",
    "## output 312 * 64\n",
    "## 1d conv, size 3 filter, stride 3, 128 filters\n",
    "## output 104 * 128\n",
    "## maxpool 2 * 1\n",
    "## output 52 * 128\n",
    "## 1d conv, size 3 filter, stride 2, 256 filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one time parameter for the model below\n",
    "## regularizer\n",
    "## l2\n",
    "ker_reg = 0.001\n",
    "act_reg = 0.1\n",
    "## kernel_initializer\n",
    "ker_init = initializers.glorot_normal(seed=None)\n",
    "## shape\n",
    "in_shape = (32000, 1)\n",
    "## learning rate\n",
    "opt = Adam()\n",
    "opt.lr = 0.0001\n",
    "##\n",
    "OUTPUT_SIZE = 10\n",
    "##\n",
    "epochs = 25\n",
    "##\n",
    "SEED = 2018\n",
    "## callback\n",
    "model_callback = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model\n",
    "## resample data to 32000 * 1\n",
    "model = Sequential()\n",
    "## 1d conv, size 80 filter, 64 filters, stride 2\n",
    "## batch norm, batch after activation\n",
    "## maxpool 4 --> 2000 * 64\n",
    "## keras.layers.Conv1D(filters, kernel_size, strides=1, padding='valid', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "model.add(Convolution1D(filters=64, kernel_size=80, strides=2, padding='same', input_shape=in_shape, kernel_initializer=ker_init, activation='relu', kernel_regularizer=regularizers.l2(ker_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "## 1d conv, size 3 filter, 128 filters, stride 1\n",
    "## batch norm, batch after activation\n",
    "## maxpool 4 --> 250 * 128\n",
    "model.add(Convolution1D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu', kernel_regularizer=regularizers.l2(ker_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "## 1d conv, size 3 filter, 128 filters, stride 2\n",
    "## batch norm, batch after activation\n",
    "## max pool 4 -->  32 * 128\n",
    "model.add(Convolution1D(filters=256, kernel_size=3, strides=2, padding='same', activation='relu', kernel_regularizer=regularizers.l2(ker_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "## 1d conv, size 3 filter, 512 filters, stride 2\n",
    "## batch norm, batch after activation\n",
    "## average pool 16 -->  1 * 512\n",
    "model.add(Convolution1D(filters=512, kernel_size=3, strides=2, padding='same',activation='relu', kernel_regularizer=regularizers.l2(ker_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling1D(pool_size=16))\n",
    "##\n",
    "model.add(Flatten())\n",
    "## fully connected\n",
    "model.add(Dense(OUTPUT_SIZE))\n",
    "## softmax\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         5184      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 250, 256)          98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 250, 256)          1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 31, 512)           393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 31, 512)           2048      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 531,146\n",
      "Trainable params: 529,226\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## experiment\n",
    "audio_path = Path('../dataset/UrbanSound8K/audio')\n",
    "x_list = []\n",
    "y_list = []\n",
    "get_int_arr = np.vectorize(int)\n",
    "for i in range(1, 11):\n",
    "    x_arr = np.load(audio_path.joinpath('fold{}_x.npy'.format(i)))\n",
    "    y_arr = np.load(audio_path.joinpath('fold{}_y.npy'.format(i))) ## string\n",
    "    y_arr = get_int_arr(y_arr)\n",
    "#     x_base = np.zeros([0, 32000])\n",
    "#     for idx in range(0, x_arr.shape[0]):\n",
    "#         x_base = np.vstack((x_base, x_arr[idx]))\n",
    "#     save_to_npy(x_base, y_arr, i)\n",
    "#     x_list.append(x_base)\n",
    "    x_list.append(x_arr)\n",
    "    y_list.append(y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combinde (0, 32000)\n",
      "combinde (0,)\n"
     ]
    }
   ],
   "source": [
    "x_list = np.array(x_list)\n",
    "y_list = np.array(y_list)\n",
    "train_list_x = combine_samples(x_list)\n",
    "train_list_y = combine_samples(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx = np.arange(train_list_x.shape[0])\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(shuffle_idx)\n",
    "train_list_x = train_list_x[shuffle_idx]\n",
    "train_list_y = train_list_y[shuffle_idx]\n",
    "## train val test split\n",
    "val_start = int(train_list_x.shape[0] * 0.7)\n",
    "val_end = int(train_list_x.shape[0] * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list_x = train_list_x[val_start: val_end]\n",
    "val_list_y = train_list_y[val_start: val_end]\n",
    "test_list_x = train_list_x[val_end:]\n",
    "test_list_y = train_list_y[val_end:]\n",
    "train_list_x = train_list_x[: val_start]\n",
    "train_list_y = train_list_y[: val_start]\n",
    "\n",
    "train_list_y = np_utils.to_categorical(train_list_y, num_classes=10)\n",
    "val_list_y = np_utils.to_categorical(val_list_y, num_classes=10)\n",
    "test_list_y = np_utils.to_categorical(test_list_y, num_classes=10)\n",
    "\n",
    "train_list_x = np.reshape(train_list_x, [train_list_x.shape[0], train_list_x.shape[1], 1])\n",
    "val_list_x = np.reshape(val_list_x, [val_list_x.shape[0], val_list_x.shape[1], 1])\n",
    "test_list_x = np.reshape(test_list_x, [test_list_x.shape[0], test_list_x.shape[1], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## zero center\n",
    "x_train_mean = np.mean(train_list_x, axis=0)\n",
    "train_list_x = train_list_x - x_train_mean\n",
    "val_list_x = val_list_x - x_train_mean\n",
    "test_list_x = test_list_x - x_train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4179 samples, validate on 1194 samples\n",
      "Epoch 1/25\n",
      " - 15s - loss: 2.4273 - acc: 0.3759 - val_loss: 2.1744 - val_acc: 0.4958\n",
      "Epoch 2/25\n",
      " - 14s - loss: 2.0426 - acc: 0.5130 - val_loss: 2.0164 - val_acc: 0.5209\n",
      "Epoch 3/25\n",
      " - 14s - loss: 1.8697 - acc: 0.5765 - val_loss: 1.9353 - val_acc: 0.5645\n",
      "Epoch 4/25\n",
      " - 14s - loss: 1.7564 - acc: 0.6126 - val_loss: 1.8447 - val_acc: 0.5955\n",
      "Epoch 5/25\n",
      " - 14s - loss: 1.6592 - acc: 0.6466 - val_loss: 1.8643 - val_acc: 0.5737\n",
      "Epoch 6/25\n",
      " - 15s - loss: 1.6031 - acc: 0.6688 - val_loss: 1.8195 - val_acc: 0.5946\n",
      "Epoch 7/25\n",
      " - 15s - loss: 1.5219 - acc: 0.6937 - val_loss: 1.7433 - val_acc: 0.6005\n",
      "Epoch 8/25\n",
      " - 15s - loss: 1.4594 - acc: 0.7172 - val_loss: 1.7012 - val_acc: 0.6298\n",
      "Epoch 9/25\n",
      " - 16s - loss: 1.4075 - acc: 0.7320 - val_loss: 1.7399 - val_acc: 0.5980\n",
      "Epoch 10/25\n",
      " - 15s - loss: 1.3517 - acc: 0.7523 - val_loss: 1.6519 - val_acc: 0.6482\n",
      "Epoch 11/25\n",
      " - 15s - loss: 1.3028 - acc: 0.7679 - val_loss: 1.5777 - val_acc: 0.6792\n",
      "Epoch 12/25\n",
      " - 15s - loss: 1.2515 - acc: 0.7837 - val_loss: 1.6748 - val_acc: 0.6240\n",
      "Epoch 13/25\n",
      " - 15s - loss: 1.2223 - acc: 0.7997 - val_loss: 1.6800 - val_acc: 0.6323\n",
      "Epoch 14/25\n",
      " - 14s - loss: 1.1898 - acc: 0.8078 - val_loss: 1.5876 - val_acc: 0.6541\n",
      "Epoch 15/25\n",
      " - 15s - loss: 1.1518 - acc: 0.8169 - val_loss: 1.6221 - val_acc: 0.6466\n",
      "Epoch 16/25\n",
      " - 14s - loss: 1.1211 - acc: 0.8270 - val_loss: 1.5484 - val_acc: 0.6834\n",
      "Epoch 17/25\n",
      " - 14s - loss: 1.0963 - acc: 0.8325 - val_loss: 1.6328 - val_acc: 0.6323\n",
      "Epoch 18/25\n",
      " - 14s - loss: 1.0528 - acc: 0.8421 - val_loss: 1.5961 - val_acc: 0.6432\n",
      "Epoch 19/25\n",
      " - 14s - loss: 1.0377 - acc: 0.8540 - val_loss: 1.5913 - val_acc: 0.6541\n",
      "Epoch 20/25\n",
      " - 14s - loss: 1.0033 - acc: 0.8555 - val_loss: 1.6402 - val_acc: 0.6340\n",
      "Epoch 21/25\n",
      " - 14s - loss: 0.9834 - acc: 0.8631 - val_loss: 1.5383 - val_acc: 0.6683\n",
      "Epoch 22/25\n",
      " - 14s - loss: 0.9602 - acc: 0.8703 - val_loss: 1.4973 - val_acc: 0.6700\n",
      "Epoch 23/25\n",
      " - 14s - loss: 0.9498 - acc: 0.8753 - val_loss: 1.5019 - val_acc: 0.6750\n",
      "Epoch 24/25\n",
      " - 14s - loss: 0.9117 - acc: 0.8827 - val_loss: 1.4981 - val_acc: 0.6876\n",
      "Epoch 25/25\n",
      " - 14s - loss: 0.8912 - acc: 0.8875 - val_loss: 1.4981 - val_acc: 0.6834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fff61d4d0f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_list_x, train_list_y,\n",
    "          epochs=epochs,\n",
    "          verbose=2,\n",
    "          validation_data=(val_list_x, val_list_y),\n",
    "          callbacks=[model_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 4179 samples, validate on 1194 samples\n",
    "Epoch 1/25\n",
    " - 27s - loss: 2.3930 - acc: 0.3898 - val_loss: 2.2291 - val_acc: 0.4204\n",
    "Epoch 2/25\n",
    " - 14s - loss: 2.0106 - acc: 0.5279 - val_loss: 2.0354 - val_acc: 0.5067\n",
    "Epoch 3/25\n",
    " - 14s - loss: 1.8591 - acc: 0.5784 - val_loss: 1.9823 - val_acc: 0.4941\n",
    "Epoch 4/25\n",
    " - 14s - loss: 1.7572 - acc: 0.6131 - val_loss: 1.9066 - val_acc: 0.5570\n",
    "Epoch 5/25\n",
    " - 14s - loss: 1.6655 - acc: 0.6487 - val_loss: 1.8375 - val_acc: 0.5913\n",
    "Epoch 6/25\n",
    " - 14s - loss: 1.5844 - acc: 0.6671 - val_loss: 1.7749 - val_acc: 0.6022\n",
    "Epoch 7/25\n",
    " - 14s - loss: 1.5322 - acc: 0.6868 - val_loss: 1.7747 - val_acc: 0.5980\n",
    "Epoch 8/25\n",
    " - 14s - loss: 1.4601 - acc: 0.7186 - val_loss: 1.7339 - val_acc: 0.6022\n",
    "Epoch 9/25\n",
    " - 14s - loss: 1.4011 - acc: 0.7310 - val_loss: 1.7275 - val_acc: 0.6055\n",
    "Epoch 10/25\n",
    " - 14s - loss: 1.3506 - acc: 0.7523 - val_loss: 1.6713 - val_acc: 0.6323\n",
    "Epoch 11/25\n",
    " - 14s - loss: 1.3105 - acc: 0.7588 - val_loss: 1.6753 - val_acc: 0.6298\n",
    "Epoch 12/25\n",
    " - 14s - loss: 1.2634 - acc: 0.7770 - val_loss: 1.6949 - val_acc: 0.6281\n",
    "Epoch 13/25\n",
    " - 14s - loss: 1.2121 - acc: 0.8028 - val_loss: 1.6527 - val_acc: 0.6407\n",
    "Epoch 14/25\n",
    " - 14s - loss: 1.1635 - acc: 0.8186 - val_loss: 1.5837 - val_acc: 0.6575\n",
    "Epoch 15/25\n",
    " - 14s - loss: 1.1391 - acc: 0.8220 - val_loss: 1.6443 - val_acc: 0.6365\n",
    "Epoch 16/25\n",
    " - 14s - loss: 1.1070 - acc: 0.8306 - val_loss: 1.6861 - val_acc: 0.6122\n",
    "Epoch 17/25\n",
    " - 14s - loss: 1.0942 - acc: 0.8337 - val_loss: 1.5659 - val_acc: 0.6600\n",
    "Epoch 18/25\n",
    " - 14s - loss: 1.0583 - acc: 0.8478 - val_loss: 1.6476 - val_acc: 0.6290\n",
    "Epoch 19/25\n",
    " - 14s - loss: 1.0263 - acc: 0.8545 - val_loss: 1.5645 - val_acc: 0.6616\n",
    "Epoch 20/25\n",
    " - 14s - loss: 0.9994 - acc: 0.8574 - val_loss: 1.6417 - val_acc: 0.6348\n",
    "Epoch 21/25\n",
    " - 14s - loss: 0.9829 - acc: 0.8629 - val_loss: 1.6160 - val_acc: 0.6441\n",
    "Epoch 22/25\n",
    " - 14s - loss: 0.9400 - acc: 0.8789 - val_loss: 1.6271 - val_acc: 0.6516\n",
    "Epoch 23/25\n",
    " - 14s - loss: 0.9380 - acc: 0.8768 - val_loss: 1.6438 - val_acc: 0.6307\n",
    "Epoch 24/25\n",
    " - 14s - loss: 0.9090 - acc: 0.8825 - val_loss: 1.5639 - val_acc: 0.6558\n",
    "Epoch 25/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2232/2232 [==============================] - 0s 192us/step\n",
      "loss 3.5232881414420287 acc 0.3830645160222139\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_list_x, test_list_y)\n",
    "print(\"loss\", loss, \"acc\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simpletensor",
   "language": "python",
   "name": "simpletensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
